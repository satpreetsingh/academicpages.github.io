<!DOCTYPE html>
<html lang=""><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <title>Research</title>
    <meta name="description" content="Satpreet&#39;s Homepage">
    <meta name="author" content='Satpreet H. Singh'>

    <link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

    
    <link rel="stylesheet" href="/sass/researcher.min.css">

    

    
        
    
</head>

    <body><div class="container mt-5">
    <nav class="navbar navbar-expand-sm flex-column flex-sm-row text-nowrap p-0">
        <a class="navbar-brand mx-0 mr-sm-auto" href="http://satpreetsingh.github.io/" title="Satpreet H. Singh">
          
          Satpreet H. Singh
        </a>
        <div class="navbar-nav flex-row flex-wrap justify-content-center">
            
                
                
                    <a class="nav-item nav-link" href="/" title=" Home ">
                         Home 
                    </a>
                    
                        <span class="nav-item navbar-text mx-1">/</span>
                    
                
                    <a class="nav-item nav-link" href="https://www.linkedin.com/in/satpreetsingh" title="LinkedIn">
                        LinkedIn
                    </a>
                    
                        <span class="nav-item navbar-text mx-1">/</span>
                    
                
                    <a class="nav-item nav-link" href="/research" title="Research">
                        Research
                    </a>
                    
                        <span class="nav-item navbar-text mx-1">/</span>
                    
                
                    <a class="nav-item nav-link" href="https://twitter.com/tweetsatpreet" title="Twitter">
                        Twitter
                    </a>
                    
                
            
        </div>
    </nav>
</div>
<hr>
<div id="content">
<div class="container">
    <p><em>Summer 2021: I&rsquo;m on the market for RL/Agents/Equilibria, Neural-Network theory/Neuro-theory postdocs and Research Scientist/Engineer roles</em></p>
<p><a href="https://drive.google.com/file/d/1qBMdnRe6wU1r--T23ZO2_i-TodvLnfe5/view?usp=sharing">Resume/CV</a></p>
<h2 id="research">Research</h2>
<p>Current interests:</p>
<ul>
<li>Intelligent Agents, Games &amp; Reinforcement Learning</li>
<li>Recurrent Neural Networks &amp; Dynamical Systems</li>
<li>Machine Learning &amp; Data Science Algorithms</li>
<li>Theoretical &amp; Statistical Neuroscience</li>
<li>Self-organization and Brain/Biology/Nature inspired algorithms</li>
</ul>
<h3 id="phd-2017---2021expected">PhD (2017 - 2021/expected)</h3>
<ul>
<li>PhD at the University of Washington (Seattle), at the intersection of ML/RL and Computational Neuroscience.</li>
<li>Working with <a href="https://www.biology.washington.edu/people/profile/bing-w-brunton">Bingni W Brunton (UW Neurobiology)</a> and <a href="https://www.cs.washington.edu/people/faculty/rao">Rajesh PN Rao (UW Computer Science)</a>.</li>
</ul>
<h4 id="understanding-biological-plume-tracking-behavior-using-deep-reinforcement-learning">Understanding biological plume tracking behavior using deep reinforcement-learning</h4>
<p>Abstract: The ability to track odor plumes in dynamic environments is critical for flying insects following attractive odors to localize food or mates. This remarkable tracking behavior requires multimodal integration of odor, vision, and wind sensing, is robust to variations in plume statistics and wind speeds, and can often be performed over large distances. Therefore, it is challenging to study in confined experimental settings. Here we describe ongoing work to explore the space of policies effective to accomplish plume tracking, leveraging the reproducibility and interpretability of artificial agents trained in biologically motivated simulations. Specifically, we trained neural-network (NN) agents with deep reinforcement learning to locate the source of a patchy simulated plume, while varying their capacity to store past sensory stimuli. We analyzed the behavior of trained agents by inspecting successful trajectories. We then interrogated the input-output maps learned by the NNs, uncovering interpretable differences in control strategies introduced by varying sensory memory. We believe that our simulation-based approach can generate novel testable hypotheses to guide the development of targeted neuroethological experiments, as well as provide a pathway towards a mechanistic understanding of the key multimodal computations required for plume tracking.</p>
<p><img src="/oldparams-cropped.gif" alt="Constant Wind Plume Tracking"></p>
<p><a href="https://direct.mit.edu/isal/proceedings/isal2020/32/750/98465">Singh et al, 2020 (ALIFE Conference 2020 Abstract)</a></p>
<p>(Full paper in preparation)</p>
<h4 id="non-negative-matrix-factorization-game">Non-Negative Matrix Factorization Game</h4>
<p>Abstract: We present a novel game-theoretic formulation of Non-Negative Matrix Factorization (NNMF), a popular data-analysis method with many scientific and engineering applications. The game-theoretic formulation is shown to have favorable scaling and parallelization properties, while retaining reconstruction and convergence performance comparable to the traditional Multiplicative Updates algorithm.</p>
<p><a href="https://arxiv.org/abs/2104.05069">Singh et al, 2021 (Unrefereed Preprint/Extended Project Report)</a></p>
<h4 id="mining-naturalistic-human-behaviors-in-long-term-video-and-neural-recordings">Mining naturalistic human behaviors in long-term video and neural recordings</h4>
<p>Abstract: Recent technological advances in brain recording and artificial intelligence are propelling a new paradigm in neuroscience beyond the traditional controlled experiment. Rather than focusing on cued, repeated trials, naturalistic neuroscience studies neural processes underlying spontaneous behaviors performed in unconstrained settings. However, analyzing such unstructured data lacking a priori experimental design remains a significant challenge, especially when the data is multi-modal and long-term. Here we describe an automated approach for analyzing simultaneously recorded long-term, naturalistic electrocorticography (ECoG) and naturalistic behavior video data. We take a behavior-first approach to analyzing the long-term recordings. Using a combination of computer vision, discrete latent-variable modeling, and string pattern-matching on the behavioral video data, we find and annotate spontaneous human upper-limb movement events. We show results from our approach applied to data collected for 12 human subjects over 7&ndash;9 days for each subject. Our pipeline discovers and annotates over 40,000 instances of naturalistic human upper-limb movement events in the behavioral videos. Analysis of the simultaneously recorded brain data reveals neural signatures of movement that corroborate prior findings from traditional controlled experiments. We also prototype a decoder for a movement initiation detection task to demonstrate the efficacy of our pipeline as a source of training data for brain-computer interfacing applications. Our work addresses the unique data analysis challenges in studying naturalistic human behaviors, and contributes methods that may generalize to other neural recording modalities beyond ECoG. We publicly release our curated dataset, providing a resource to study naturalistic neural and behavioral variability at a scale not previously available.</p>
<p><img src="https://raw.githubusercontent.com/BruntonUWBio/mining2021/master/right_only_1x4_boomerang.gif" alt="Right Wrist"></p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0165027021001345">Singh et al, 2021 (Journal of Neuroscience Methods)</a></p>
<p><a href="https://github.com/BruntonUWBio/mining2021">Code, data, preprint and additional videos</a></p>
<p><a href="https://twitter.com/tweetsatpreet/status/1276201158575452160">#tweeprint</a> on this paper:</p>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our new preprint titled “Investigating naturalistic hand movements by behavior mining in long-term video and neural recordings” is now online: <a href="https://t.co/46FsBMFnV1">https://t.co/46FsBMFnV1</a><br>Joint work with <a href="https://twitter.com/stevenmpeterson?ref_src=twsrc%5Etfw">@stevenmpeterson</a>, <a href="https://twitter.com/RajeshPNRao?ref_src=twsrc%5Etfw">@RajeshPNRao</a> &amp; <a href="https://twitter.com/bingbrunton?ref_src=twsrc%5Etfw">@bingbrunton</a> <br>1/4 <a href="https://t.co/6360Dw8TMs">pic.twitter.com/6360Dw8TMs</a></p>&mdash; Satpreet Singh (@tweetsatpreet) <a href="https://twitter.com/tweetsatpreet/status/1276201158575452160?ref_src=twsrc%5Etfw">June 25, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<h3 id="before-phd">Before PhD</h3>
<ul>
<li><a href="https://par.nsf.gov/biblio/10049769">Cerenkov: Computational elucidation of the regulatory noncoding variome, </a> at the 8th ACM International Conference on Bioinformatics, Computational Biology,and Health Informatics (2017)</li>
<li><a href="https://ir.library.oregonstate.edu/concern/graduate_thesis_or_dissertations/k0698d22b">Visualization and Analysis of Sensor Data for Detecting Microclimate Cold Air Pools</a> Oregon State University MS Thesis (2017)</li>
<li><a href="https://iwaponline.com/jh/article/15/2/580/3447/Hydro-NEXRAD-2-real-time-access-to-customized">Hydro-NEXRAD-2: real-time access to customized radar-rainfall for hydrologic applications</a> Journal of Hydroinformatics (2013)</li>
</ul>

</div>

        </div><div id="footer" class="mb-5">
    
        <hr>
        <div class="container text-center">
            <a href="https://github.com/ojroques/hugo-researcher" title="Hugo : Researcher"><small>Hugo : Researcher</small></a>
        </div>
    
</div>
</body>
</html>
